{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "DemoSegmenter",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cedro3/others2/blob/main/DemoSegmenter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5mW_XiR-x8a"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uv4sZ0v9_W6H"
      },
      "source": [
        "**Environment Setup**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJwDpfnR0Tyl"
      },
      "source": [
        "%%bash\n",
        "# Colab-specific setup\n",
        "!(stat -t /usr/local/lib/*/dist-packages/google/colab > /dev/null 2>&1) && exit \n",
        "pip install yacs 2>&1 >> install.log\n",
        "git init 2>&1 >> install.log\n",
        "git remote add origin https://github.com/CSAILVision/semantic-segmentation-pytorch.git 2>> install.log\n",
        "git pull origin master 2>&1 >> install.log\n",
        "DOWNLOAD_ONLY=1 ./demo_test.sh 2>> install.log"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0n-UmiA_G-R"
      },
      "source": [
        "**Imports and utility functions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-Lj9g_E0Tym"
      },
      "source": [
        "# System libs\n",
        "import os, csv, torch, numpy, scipy.io, PIL.Image, torchvision.transforms\n",
        "# Our libs\n",
        "from mit_semseg.models import ModelBuilder, SegmentationModule\n",
        "from mit_semseg.utils import colorEncode\n",
        "\n",
        "colors = scipy.io.loadmat('data/color150.mat')['colors']\n",
        "names = {}\n",
        "with open('data/object150_info.csv') as f:\n",
        "    reader = csv.reader(f)\n",
        "    next(reader)\n",
        "    for row in reader:\n",
        "        names[int(row[0])] = row[5].split(\";\")[0]\n",
        "\n",
        "def visualize_result(img, pred, index=None):\n",
        "    # filter prediction class if requested\n",
        "    if index is not None:\n",
        "        pred = pred.copy()\n",
        "        pred[pred != index] = -1\n",
        "        print(f'{names[index+1]}:')\n",
        "        \n",
        "    # colorize prediction\n",
        "    pred_color = colorEncode(pred, colors).astype(numpy.uint8)\n",
        "\n",
        "    # aggregate images and save\n",
        "    im_vis = numpy.concatenate((img, pred_color), axis=1)\n",
        "    display(PIL.Image.fromarray(im_vis))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eql3xHZt0Tyn"
      },
      "source": [
        "**Loading the segmentation model**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrJ91vrG0Tyn"
      },
      "source": [
        "# Network Builders\n",
        "net_encoder = ModelBuilder.build_encoder(\n",
        "    arch='resnet50dilated',\n",
        "    fc_dim=2048,\n",
        "    weights='ckpt/ade20k-resnet50dilated-ppm_deepsup/encoder_epoch_20.pth')\n",
        "net_decoder = ModelBuilder.build_decoder(\n",
        "    arch='ppm_deepsup',\n",
        "    fc_dim=2048,\n",
        "    num_class=150,\n",
        "    weights='ckpt/ade20k-resnet50dilated-ppm_deepsup/decoder_epoch_20.pth',\n",
        "    use_softmax=True)\n",
        "\n",
        "crit = torch.nn.NLLLoss(ignore_index=-1)\n",
        "segmentation_module = SegmentationModule(net_encoder, net_decoder, crit)\n",
        "segmentation_module.eval()\n",
        "segmentation_module.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWnCw0If_gGj"
      },
      "source": [
        "# For image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqZz74PF0Tyo"
      },
      "source": [
        "**Load test data**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkBlYcpC0Typ"
      },
      "source": [
        "# Load and normalize one image as a singleton tensor batch\n",
        "pil_to_tensor = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    torchvision.transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406], # These are RGB mean+std values\n",
        "        std=[0.229, 0.224, 0.225])  # across a large photo dataset.\n",
        "])\n",
        "pil_image = PIL.Image.open('ADE_val_00001519.jpg').convert('RGB')\n",
        "img_original = numpy.array(pil_image)\n",
        "img_data = pil_to_tensor(pil_image)\n",
        "singleton_batch = {'img_data': img_data[None].cuda()}\n",
        "output_size = img_data.shape[1:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdAmRgQt0Typ"
      },
      "source": [
        "**Run the Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0SZaJfQ0Typ",
        "scrolled": false
      },
      "source": [
        "# Run the segmentation at the highest resolution.\n",
        "with torch.no_grad():\n",
        "    scores = segmentation_module(singleton_batch, segSize=output_size)\n",
        "    \n",
        "# Get the predicted scores for each pixel\n",
        "_, pred = torch.max(scores, dim=1)\n",
        "pred = pred.cpu()[0].numpy()\n",
        "visualize_result(img_original, pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEyXy3o-0Tyq"
      },
      "source": [
        "**Showing classes individually**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnYY5f680Tyq"
      },
      "source": [
        "# Top classes in answer\n",
        "predicted_classes = numpy.bincount(pred.flatten()).argsort()[::-1]\n",
        "for c in predicted_classes[:15]:\n",
        "    visualize_result(img_original, pred, c)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPSQ-6yK-ISM"
      },
      "source": [
        "# For movie"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfHynVnK14ok"
      },
      "source": [
        "# サンプルビデオをダウンロード\n",
        "import gdown\n",
        "gdown.download('https://drive.google.com/uc?id=1cfa4R-0Zwd2Te5-qBWe9oNRKQ_pEUr0z', 'road.mp4', quiet=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kR8a_wmLv7__"
      },
      "source": [
        "# サンプルビデオを静止画に変換\n",
        "import os\n",
        "import shutil\n",
        "import cv2\n",
        " \n",
        "def video_2_images(video_file= './road.mp4',   # ビデオ指定\n",
        "                   image_dir='./images/', \n",
        "                   image_file='%s.jpg'):  \n",
        " \n",
        "    # Initial setting\n",
        "    i = 0\n",
        "    interval = 3\n",
        "    length = 600  # 最大フレーム数\n",
        "    \n",
        "    cap = cv2.VideoCapture(video_file)\n",
        "    while(cap.isOpened()):\n",
        "        flag, frame = cap.read()  \n",
        "        if flag == False:  \n",
        "                break\n",
        "        if i == length*interval:\n",
        "                break\n",
        "        if i % interval == 0: \n",
        "           cv2.imwrite(image_dir+image_file % str(int(i/interval)).zfill(6), frame)\n",
        "        i += 1 \n",
        "    cap.release()  \n",
        "\n",
        "# imagesフォルダーリセット\n",
        "if os.path.isdir('images'):\n",
        "    shutil.rmtree('images')\n",
        "os.makedirs('images', exist_ok=True)\n",
        "\n",
        "# ビデオを静止画に変換\n",
        "video_2_images()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRRsELU4udx-"
      },
      "source": [
        "# 静止画をセグメンテーションに変換\n",
        "\n",
        "# 正規化データをロード\n",
        "pil_to_tensor = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    torchvision.transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406], # These are RGB mean+std values\n",
        "        std=[0.229, 0.224, 0.225])  # across a large photo dataset.\n",
        "])\n",
        "\n",
        "# imagesフォルダーの静止画を1枚づつ処理\n",
        "from tqdm import tqdm\n",
        "import glob\n",
        "files = glob.glob('./images/*.jpg')\n",
        "files.sort()\n",
        "\n",
        "for file in tqdm(files):\n",
        "    pil_image = PIL.Image.open(file).convert('RGB')\n",
        "    img_original = numpy.array(pil_image)\n",
        "    img_data = pil_to_tensor(pil_image)\n",
        "    singleton_batch = {'img_data': img_data[None].cuda()}\n",
        "    output_size = img_data.shape[1:]\n",
        "\n",
        "    # セグメンテーションの実行\n",
        "    with torch.no_grad():\n",
        "        scores = segmentation_module(singleton_batch, segSize=output_size)\n",
        "    \n",
        "    # 予測結果の処理\n",
        "    _, pred = torch.max(scores, dim=1)\n",
        "    pred = pred.cpu()[0].numpy()\n",
        "    pred_color = colorEncode(pred, colors).astype(numpy.uint8)\n",
        "    im_vis = numpy.concatenate((img_original, pred_color), axis=1)  # オリジナルと横連結\n",
        "    #im_vis = numpy.concatenate((pred_color, img_original), axis=0)  # オリジナルと縦連結\n",
        "    PIL.Image.fromarray(im_vis).save(file) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpJ-104U4Fzq"
      },
      "source": [
        "# output.mp4をリセット\n",
        "if os.path.exists('./output.mp4'):\n",
        "   os.remove('./output.mp4')\n",
        "\n",
        "# 実写＋セグメンテーションをmp4動画に変換\n",
        "!ffmpeg -r 10 -i images/%06d.jpg -vcodec libx264 -pix_fmt yuv420p output.mp4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uk_KCWp041gA"
      },
      "source": [
        "# mp4動画の再生\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "\n",
        "mp4 = open('./output.mp4', 'rb').read()\n",
        "data_url = 'data:video/mp4;base64,' + b64encode(mp4).decode()\n",
        "HTML(f\"\"\"\n",
        "<video width=\"100%\" height=\"100%\" controls>\n",
        "      <source src=\"{data_url}\" type=\"video/mp4\">\n",
        "</video>\"\"\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}