{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "name": "AnimeGANV2_for_face",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cedro3/others2/blob/main/AnimeGANV2_for_face.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWEN4yiB5gjz"
      },
      "source": [
        "# AnimeGANV2 for face"
      ],
      "id": "BWEN4yiB5gjz"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3f40d528",
        "cellView": "form"
      },
      "source": [
        "#@title セットアップ\n",
        "\n",
        "# load Face2Paint model\n",
        "import torch \n",
        "from PIL import Image\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = torch.hub.load(\"bryandlee/animegan2-pytorch:main\", \"generator\", device=device).eval()\n",
        "face2paint = torch.hub.load(\"bryandlee/animegan2-pytorch:main\", \"face2paint\", device=device, side_by_side=True)\n",
        "\n",
        "\n",
        "# Face Detector & FFHQ-style Alignment\n",
        "# https://github.com/woctezuma/stylegan2-projecting-images\n",
        "import os\n",
        "import dlib\n",
        "import collections\n",
        "from typing import Union, List\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def get_dlib_face_detector(predictor_path: str = \"shape_predictor_68_face_landmarks.dat\"):\n",
        "\n",
        "    if not os.path.isfile(predictor_path):\n",
        "        model_file = \"shape_predictor_68_face_landmarks.dat.bz2\"\n",
        "        os.system(f\"wget http://dlib.net/files/{model_file}\")\n",
        "        os.system(f\"bzip2 -dk {model_file}\")\n",
        "\n",
        "    detector = dlib.get_frontal_face_detector()\n",
        "    shape_predictor = dlib.shape_predictor(predictor_path)\n",
        "\n",
        "    def detect_face_landmarks(img: Union[Image.Image, np.ndarray]):\n",
        "        if isinstance(img, Image.Image):\n",
        "            img = np.array(img)\n",
        "        faces = []\n",
        "        dets = detector(img)\n",
        "        for d in dets:\n",
        "            shape = shape_predictor(img, d)\n",
        "            faces.append(np.array([[v.x, v.y] for v in shape.parts()]))\n",
        "        return faces\n",
        "    \n",
        "    return detect_face_landmarks\n",
        "\n",
        "\n",
        "def display_facial_landmarks(\n",
        "    img: Image, \n",
        "    landmarks: List[np.ndarray],\n",
        "    fig_size=[15, 15]\n",
        "):\n",
        "    plot_style = dict(\n",
        "        marker='o',\n",
        "        markersize=4,\n",
        "        linestyle='-',\n",
        "        lw=2\n",
        "    )\n",
        "    pred_type = collections.namedtuple('prediction_type', ['slice', 'color'])\n",
        "    pred_types = {\n",
        "        'face': pred_type(slice(0, 17), (0.682, 0.780, 0.909, 0.5)),\n",
        "        'eyebrow1': pred_type(slice(17, 22), (1.0, 0.498, 0.055, 0.4)),\n",
        "        'eyebrow2': pred_type(slice(22, 27), (1.0, 0.498, 0.055, 0.4)),\n",
        "        'nose': pred_type(slice(27, 31), (0.345, 0.239, 0.443, 0.4)),\n",
        "        'nostril': pred_type(slice(31, 36), (0.345, 0.239, 0.443, 0.4)),\n",
        "        'eye1': pred_type(slice(36, 42), (0.596, 0.875, 0.541, 0.3)),\n",
        "        'eye2': pred_type(slice(42, 48), (0.596, 0.875, 0.541, 0.3)),\n",
        "        'lips': pred_type(slice(48, 60), (0.596, 0.875, 0.541, 0.3)),\n",
        "        'teeth': pred_type(slice(60, 68), (0.596, 0.875, 0.541, 0.4))\n",
        "    }\n",
        "\n",
        "    fig = plt.figure(figsize=fig_size)\n",
        "    ax = fig.add_subplot(1, 1, 1)\n",
        "    ax.imshow(img)\n",
        "    ax.axis('off')\n",
        "\n",
        "    for face in landmarks:\n",
        "        for pred_type in pred_types.values():\n",
        "            ax.plot(\n",
        "                face[pred_type.slice, 0],\n",
        "                face[pred_type.slice, 1],\n",
        "                color=pred_type.color, **plot_style\n",
        "            )\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "# https://github.com/NVlabs/ffhq-dataset/blob/master/download_ffhq.py\n",
        "\n",
        "import PIL.Image\n",
        "import PIL.ImageFile\n",
        "import numpy as np\n",
        "import scipy.ndimage\n",
        "\n",
        "\n",
        "def align_and_crop_face(\n",
        "    img: Image.Image,\n",
        "    landmarks: np.ndarray,\n",
        "    expand: float = 1.0,\n",
        "    output_size: int = 1024, \n",
        "    transform_size: int = 4096,\n",
        "    enable_padding: bool = True,\n",
        "):\n",
        "    # Parse landmarks.\n",
        "    # pylint: disable=unused-variable\n",
        "    lm = landmarks\n",
        "    lm_chin          = lm[0  : 17]  # left-right\n",
        "    lm_eyebrow_left  = lm[17 : 22]  # left-right\n",
        "    lm_eyebrow_right = lm[22 : 27]  # left-right\n",
        "    lm_nose          = lm[27 : 31]  # top-down\n",
        "    lm_nostrils      = lm[31 : 36]  # top-down\n",
        "    lm_eye_left      = lm[36 : 42]  # left-clockwise\n",
        "    lm_eye_right     = lm[42 : 48]  # left-clockwise\n",
        "    lm_mouth_outer   = lm[48 : 60]  # left-clockwise\n",
        "    lm_mouth_inner   = lm[60 : 68]  # left-clockwise\n",
        "\n",
        "    # Calculate auxiliary vectors.\n",
        "    eye_left     = np.mean(lm_eye_left, axis=0)\n",
        "    eye_right    = np.mean(lm_eye_right, axis=0)\n",
        "    eye_avg      = (eye_left + eye_right) * 0.5\n",
        "    eye_to_eye   = eye_right - eye_left\n",
        "    mouth_left   = lm_mouth_outer[0]\n",
        "    mouth_right  = lm_mouth_outer[6]\n",
        "    mouth_avg    = (mouth_left + mouth_right) * 0.5\n",
        "    eye_to_mouth = mouth_avg - eye_avg\n",
        "\n",
        "    # Choose oriented crop rectangle.\n",
        "    x = eye_to_eye - np.flipud(eye_to_mouth) * [-1, 1]\n",
        "    x /= np.hypot(*x)\n",
        "    x *= max(np.hypot(*eye_to_eye) * 2.0, np.hypot(*eye_to_mouth) * 1.8)\n",
        "    x *= expand\n",
        "    y = np.flipud(x) * [-1, 1]\n",
        "    c = eye_avg + eye_to_mouth * 0.1\n",
        "    quad = np.stack([c - x - y, c - x + y, c + x + y, c + x - y])\n",
        "    qsize = np.hypot(*x) * 2\n",
        "\n",
        "    # Shrink.\n",
        "    shrink = int(np.floor(qsize / output_size * 0.5))\n",
        "    if shrink > 1:\n",
        "        rsize = (int(np.rint(float(img.size[0]) / shrink)), int(np.rint(float(img.size[1]) / shrink)))\n",
        "        img = img.resize(rsize, PIL.Image.ANTIALIAS)\n",
        "        quad /= shrink\n",
        "        qsize /= shrink\n",
        "\n",
        "    # Crop.\n",
        "    border = max(int(np.rint(qsize * 0.1)), 3)\n",
        "    crop = (int(np.floor(min(quad[:,0]))), int(np.floor(min(quad[:,1]))), int(np.ceil(max(quad[:,0]))), int(np.ceil(max(quad[:,1]))))\n",
        "    crop = (max(crop[0] - border, 0), max(crop[1] - border, 0), min(crop[2] + border, img.size[0]), min(crop[3] + border, img.size[1]))\n",
        "    if crop[2] - crop[0] < img.size[0] or crop[3] - crop[1] < img.size[1]:\n",
        "        img = img.crop(crop)\n",
        "        quad -= crop[0:2]\n",
        "\n",
        "    # Pad.\n",
        "    pad = (int(np.floor(min(quad[:,0]))), int(np.floor(min(quad[:,1]))), int(np.ceil(max(quad[:,0]))), int(np.ceil(max(quad[:,1]))))\n",
        "    pad = (max(-pad[0] + border, 0), max(-pad[1] + border, 0), max(pad[2] - img.size[0] + border, 0), max(pad[3] - img.size[1] + border, 0))\n",
        "    if enable_padding and max(pad) > border - 4:\n",
        "        pad = np.maximum(pad, int(np.rint(qsize * 0.3)))\n",
        "        img = np.pad(np.float32(img), ((pad[1], pad[3]), (pad[0], pad[2]), (0, 0)), 'reflect')\n",
        "        h, w, _ = img.shape\n",
        "        y, x, _ = np.ogrid[:h, :w, :1]\n",
        "        mask = np.maximum(1.0 - np.minimum(np.float32(x) / pad[0], np.float32(w-1-x) / pad[2]), 1.0 - np.minimum(np.float32(y) / pad[1], np.float32(h-1-y) / pad[3]))\n",
        "        blur = qsize * 0.02\n",
        "        img += (scipy.ndimage.gaussian_filter(img, [blur, blur, 0]) - img) * np.clip(mask * 3.0 + 1.0, 0.0, 1.0)\n",
        "        img += (np.median(img, axis=(0,1)) - img) * np.clip(mask, 0.0, 1.0)\n",
        "        img = PIL.Image.fromarray(np.uint8(np.clip(np.rint(img), 0, 255)), 'RGB')\n",
        "        quad += pad[:2]\n",
        "\n",
        "    # Transform.\n",
        "    img = img.transform((transform_size, transform_size), PIL.Image.QUAD, (quad + 0.5).flatten(), PIL.Image.BILINEAR)\n",
        "    if output_size < transform_size:\n",
        "        img = img.resize((output_size, output_size), PIL.Image.ANTIALIAS)\n",
        "\n",
        "    return img\n",
        "\n",
        "\n",
        "# define display function\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "def display_pic(folder):\n",
        "    fig = plt.figure(figsize=(30, 40))\n",
        "    files = os.listdir(folder)\n",
        "    files.sort()\n",
        "    for i, file in enumerate(files):\n",
        "        if file == '.ipynb_checkpoints':\n",
        "          continue  \n",
        "        img = Image.open(folder+'/'+file) \n",
        "        images = np.asarray(img)\n",
        "        ax = fig.add_subplot(10, 10, i+1, xticks=[], yticks=[])\n",
        "        image_plt = np.array(images)\n",
        "        ax.imshow(image_plt)\n",
        "        ax.set_xlabel(file, fontsize=15)               \n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "# サンプルデータをダウンロード\n",
        "import gdown\n",
        "gdown.download('https://drive.google.com/uc?id=1CDSfi5jZ_uqOYFZqe8n_CGkZc-XhyoJ6', 'sample.zip', quiet=False)\n",
        "! unzip sample.zip"
      ],
      "id": "3f40d528",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gjnXo2V6e1-"
      },
      "source": [
        "**自分の画像を使う場合はpicフォルダーにアップロード**"
      ],
      "id": "3gjnXo2V6e1-"
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "u0AP5LJ_X4Iz"
      },
      "source": [
        "#@title サンプル画像表示\n",
        "display_pic('pic')"
      ],
      "id": "u0AP5LJ_X4Iz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whGJAsWY84FY"
      },
      "source": [
        "**side_by_sideのチェックを外すとアニメ単体になる**"
      ],
      "id": "whGJAsWY84FY"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "039c54ca",
        "cellView": "form"
      },
      "source": [
        "#@title 画像をアニメへ変換\n",
        "import cv2\n",
        "input = '004.jpg' #@param {type:\"string\"}\n",
        "side_by_side = True #@param {type:\"boolean\"}\n",
        "img = Image.open('pic/'+input).convert(\"RGB\")\n",
        "\n",
        "face_detector = get_dlib_face_detector()\n",
        "landmarks = face_detector(img)\n",
        "\n",
        "face = align_and_crop_face(img, landmarks[0], expand=1.3)\n",
        "output = face2paint(model=model, img=face, size=512, side_by_side=side_by_side)\n",
        "output.save('output.jpg')\n",
        "display(output)\n"
      ],
      "id": "039c54ca",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "KJmn6B7aflqc"
      },
      "source": [
        "#@title アニメのダウンロード\n",
        "from google.colab import files\n",
        "files.download('output.jpg')"
      ],
      "id": "KJmn6B7aflqc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9nQAyna8xKz"
      },
      "source": [
        "#-------------------------------------------------#"
      ],
      "id": "P9nQAyna8xKz"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F94-QDtJ6Snn"
      },
      "source": [
        "**自分の動画を使う場合はvideoフォルダーにアップロード**\\\n",
        "**動画はRVM処理するのがおすすめ（下記リンク参照）**\\\n",
        "http://cedro3.com/ai/rvm/"
      ],
      "id": "F94-QDtJ6Snn"
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "Ej0JC8Hp32n-"
      },
      "source": [
        "#@title サンプル動画の再生\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "\n",
        "mp4 = open('./video/mark.mp4', 'rb').read()\n",
        "data_url = 'data:video/mp4;base64,' + b64encode(mp4).decode()\n",
        "HTML(f\"\"\"\n",
        "<video width=\"70%\" height=\"70%\" controls>\n",
        "      <source src=\"{data_url}\" type=\"video/mp4\">\n",
        "</video>\"\"\")"
      ],
      "id": "Ej0JC8Hp32n-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6l9YE6EKJSsS",
        "cellView": "form"
      },
      "source": [
        "#@title 動画をフレームにバラす\n",
        "video_name = 'mark.mp4' #@param {type:\"string\"}\n",
        "video_file = 'video/'+video_name\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import cv2\n",
        "\n",
        "# input.mp4にコピー\n",
        "shutil.copy(video_file, 'input.mp4')\n",
        "\n",
        "# flamesフォルダーリセット\n",
        "if os.path.isdir('flames'):\n",
        "    shutil.rmtree('flames')\n",
        "os.makedirs('flames', exist_ok=True)\n",
        " \n",
        "def video_2_images(video_file= video_file,   # ビデオの指定\n",
        "                   image_dir='./flames/', \n",
        "                   image_file='%s.jpg'):  \n",
        " \n",
        "    shutil.copy(video_file, 'input.mp4')  ####\n",
        "\n",
        "    # Initial setting\n",
        "    i = 0\n",
        "    interval = 3\n",
        "    length = 100  # 最大フレーム数\n",
        "    \n",
        "    cap = cv2.VideoCapture(video_file)\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)  # fps取得\n",
        "\n",
        "    while(cap.isOpened()):\n",
        "        flag, frame = cap.read()  \n",
        "        if flag == False:  \n",
        "                break\n",
        "        if i == length*interval:\n",
        "                break\n",
        "        if i % interval == 0:    \n",
        "           cv2.imwrite(image_dir+image_file % str(int(i/interval)).zfill(6), frame)\n",
        "        i += 1 \n",
        "    cap.release()\n",
        "    return fps, i, interval\n",
        " \n",
        "fps, i, interval = video_2_images()\n",
        "print('fps = ', fps)\n",
        "print('flames = ', i)\n",
        "print('interval = ', interval)\n",
        " "
      ],
      "id": "6l9YE6EKJSsS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6q8O2V-WPFuI",
        "cellView": "form"
      },
      "source": [
        "#@title フレームをアニメに変換\n",
        "import os\n",
        "import shutil\n",
        "import cv2\n",
        "\n",
        "# images folder reset\n",
        "if os.path.isdir('out'):\n",
        "    shutil.rmtree('out')\n",
        "os.makedirs('out', exist_ok=True)\n",
        "\n",
        "import glob\n",
        "files = glob.glob('flames/*.jpg')\n",
        "files.sort()\n",
        "\n",
        "face_detector = get_dlib_face_detector()\n",
        "\n",
        "from tqdm import tqdm\n",
        "for i, file in enumerate(tqdm(files)):\n",
        "    img = Image.open(file).convert(\"RGB\")\n",
        "    #face_detector = get_dlib_face_detector()\n",
        "    landmarks = face_detector(img)\n",
        "\n",
        "    face = align_and_crop_face(img, landmarks[0], expand=1.3)\n",
        "    output = face2paint(model=model, img=face, size=512)\n",
        "    output.save('out/'+str(i).zfill(6)+'.jpg')"
      ],
      "id": "6q8O2V-WPFuI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rczOn-f5SIUv",
        "cellView": "form"
      },
      "source": [
        "#@title アニメから動画を作成\n",
        "# リセットファイル\n",
        "if os.path.exists('./output.mp4'):\n",
        "   os.remove('./output.mp4')\n",
        "\n",
        "speed = fps/interval\n",
        "\n",
        "# アニメ画をmp4動画(output.mp4)に変換する\n",
        "! ffmpeg -r $speed -i out/%06d.jpg -vcodec libx264 -pix_fmt yuv420p -loglevel error output.mp4"
      ],
      "id": "rczOn-f5SIUv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "4egpzmhh4fiB"
      },
      "source": [
        "#@title 動画の再生\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "\n",
        "mp4 = open('./output.mp4', 'rb').read()\n",
        "data_url = 'data:video/mp4;base64,' + b64encode(mp4).decode()\n",
        "HTML(f\"\"\"\n",
        "<video width=\"70%\" height=\"70%\" controls>\n",
        "      <source src=\"{data_url}\" type=\"video/mp4\">\n",
        "</video>\"\"\")"
      ],
      "id": "4egpzmhh4fiB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "szYJa76p48az"
      },
      "source": [
        "#@title 動画のダウンロード\n",
        "from google.colab import files\n",
        "files.download('output.mp4')"
      ],
      "id": "szYJa76p48az",
      "execution_count": null,
      "outputs": []
    }
  ]
}